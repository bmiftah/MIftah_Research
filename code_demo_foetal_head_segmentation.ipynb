{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "code demo foetal-head-segmentation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmiftah/MIftah_Research/blob/master/code_demo_foetal_head_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "razSQQQs0Vbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb6c478-feea-47df-84cb-483df4f2c923"
      },
      "source": [
        "!git clone https://github.com/haochen23/foetal-head-segmentation.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'foetal-head-segmentation'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 74 (delta 1), reused 0 (delta 0), pack-reused 69\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCVG3TDP0XXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7a85b2-833d-4d2d-9b1b-c4ef9f2845b2"
      },
      "source": [
        "#!%cd foetal-head-segmentation/\n",
        "#!ls\n",
        "#!pip install patool\n",
        "#import patoolib\n",
        "#patoolib.extract_archive(\"test.rar\",outdir=\"/content/foetal-head-segmentation/foetal-head-us/\")\n",
        "#%cd foetal-head-us/\n",
        "#!ls\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting test.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/foetal-head-segmentation/foetal-head-us/test.rar\n",
            "patool:     with cwd='/content/foetal-head-segmentation/foetal-head-us/'\n",
            "patool: ... test.rar extracted to `/content/foetal-head-segmentation/foetal-head-us/'.\n",
            "test.rar  test_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPS1o01ADLGV"
      },
      "source": [
        "!cp -r ../foetal-head-us/ ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OBeMqPq_355"
      },
      "source": [
        "I interrupted the next training cell to save time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeEEyc310ewi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52cc163e-3878-4e30-ac31-d107fac11b22"
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-03 04:05:12.000966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Number of US training images is 999\n",
            "Number of US training masks is 999\n",
            "2020-07-03 04:05:37.007407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-03 04:05:37.010794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.011363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-07-03 04:05:37.011431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-03 04:05:37.013228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-03 04:05:37.015009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-03 04:05:37.015409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-03 04:05:37.017251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-03 04:05:37.018122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-03 04:05:37.021639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-03 04:05:37.021799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.022409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.022939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-07-03 04:05:37.028251: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-07-03 04:05:37.028478: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18eaa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-03 04:05:37.028517: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-03 04:05:37.073444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.074181: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18ead80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-03 04:05:37.074218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-07-03 04:05:37.074478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.075019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-07-03 04:05:37.075097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-03 04:05:37.075187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-03 04:05:37.075236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-03 04:05:37.075289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-03 04:05:37.075339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-03 04:05:37.075400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-03 04:05:37.075451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-03 04:05:37.075651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.076253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.076934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-07-03 04:05:37.077008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-03 04:05:37.524026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-03 04:05:37.524090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-07-03 04:05:37.524122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-07-03 04:05:37.524418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.525077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-03 04:05:37.525624: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-03 04:05:37.525690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6575 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From train.py:143: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/50\n",
            "2020-07-03 04:05:48.165926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-03 04:05:49.424190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.5060 - dice_coef: 0.5060\n",
            "Epoch 00001: val_dice_coef improved from -inf to 0.36074, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 154s 619ms/step - loss: -0.5060 - dice_coef: 0.5060 - val_loss: -0.3607 - val_dice_coef: 0.3607\n",
            "Epoch 2/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.7539 - dice_coef: 0.7539\n",
            "Epoch 00002: val_dice_coef did not improve from 0.36074\n",
            "249/249 [==============================] - 153s 613ms/step - loss: -0.7539 - dice_coef: 0.7539 - val_loss: -0.2303 - val_dice_coef: 0.2303\n",
            "Epoch 3/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.7966 - dice_coef: 0.7966\n",
            "Epoch 00003: val_dice_coef improved from 0.36074 to 0.56724, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 616ms/step - loss: -0.7966 - dice_coef: 0.7966 - val_loss: -0.5672 - val_dice_coef: 0.5672\n",
            "Epoch 4/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8194 - dice_coef: 0.8194\n",
            "Epoch 00004: val_dice_coef improved from 0.56724 to 0.76260, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 616ms/step - loss: -0.8194 - dice_coef: 0.8194 - val_loss: -0.7626 - val_dice_coef: 0.7626\n",
            "Epoch 5/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8349 - dice_coef: 0.8349\n",
            "Epoch 00005: val_dice_coef improved from 0.76260 to 0.82093, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 616ms/step - loss: -0.8349 - dice_coef: 0.8349 - val_loss: -0.8209 - val_dice_coef: 0.8209\n",
            "Epoch 6/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8471 - dice_coef: 0.8471\n",
            "Epoch 00006: val_dice_coef improved from 0.82093 to 0.83611, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 616ms/step - loss: -0.8471 - dice_coef: 0.8471 - val_loss: -0.8361 - val_dice_coef: 0.8361\n",
            "Epoch 7/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8577 - dice_coef: 0.8577\n",
            "Epoch 00007: val_dice_coef improved from 0.83611 to 0.85121, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 616ms/step - loss: -0.8577 - dice_coef: 0.8577 - val_loss: -0.8512 - val_dice_coef: 0.8512\n",
            "Epoch 8/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8667 - dice_coef: 0.8667\n",
            "Epoch 00008: val_dice_coef improved from 0.85121 to 0.86474, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 616ms/step - loss: -0.8667 - dice_coef: 0.8667 - val_loss: -0.8647 - val_dice_coef: 0.8647\n",
            "Epoch 9/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8751 - dice_coef: 0.8751\n",
            "Epoch 00009: val_dice_coef did not improve from 0.86474\n",
            "249/249 [==============================] - 152s 612ms/step - loss: -0.8751 - dice_coef: 0.8751 - val_loss: -0.8598 - val_dice_coef: 0.8598\n",
            "Epoch 10/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8824 - dice_coef: 0.8824\n",
            "Epoch 00010: val_dice_coef improved from 0.86474 to 0.87845, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 613ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -0.8784 - val_dice_coef: 0.8784\n",
            "Epoch 11/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8893 - dice_coef: 0.8893\n",
            "Epoch 00011: val_dice_coef improved from 0.87845 to 0.88620, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 152s 610ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.8862 - val_dice_coef: 0.8862\n",
            "Epoch 12/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8955 - dice_coef: 0.8955\n",
            "Epoch 00012: val_dice_coef improved from 0.88620 to 0.89309, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 614ms/step - loss: -0.8955 - dice_coef: 0.8955 - val_loss: -0.8931 - val_dice_coef: 0.8931\n",
            "Epoch 13/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9016 - dice_coef: 0.9016\n",
            "Epoch 00013: val_dice_coef improved from 0.89309 to 0.89975, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 613ms/step - loss: -0.9016 - dice_coef: 0.9016 - val_loss: -0.8998 - val_dice_coef: 0.8998\n",
            "Epoch 14/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9066 - dice_coef: 0.9066\n",
            "Epoch 00014: val_dice_coef improved from 0.89975 to 0.90558, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 153s 616ms/step - loss: -0.9066 - dice_coef: 0.9066 - val_loss: -0.9056 - val_dice_coef: 0.9056\n",
            "Epoch 15/50\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9119 - dice_coef: 0.9119\n",
            "Epoch 00015: val_dice_coef improved from 0.90558 to 0.91044, saving model to best_model_224_res.h5\n",
            "249/249 [==============================] - 154s 617ms/step - loss: -0.9119 - dice_coef: 0.9119 - val_loss: -0.9104 - val_dice_coef: 0.9104\n",
            "Epoch 16/50\n",
            "200/249 [=======================>......] - ETA: 27s - loss: -0.9163 - dice_coef: 0.9163Traceback (most recent call last):\n",
            "  File \"train.py\", line 143, in <module>\n",
            "    validation_data = val_gen, validation_steps = validation_steps,callbacks=[checkpointer])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1479, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 855, in fit\n",
            "    callbacks.on_train_batch_end(step, logs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 389, in on_train_batch_end\n",
            "    logs = self._process_logs(logs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\", line 265, in _process_logs\n",
            "    return tf_utils.to_numpy_or_python_type(logs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\", line 523, in to_numpy_or_python_type\n",
            "    return nest.map_structure(_to_single_numpy_or_python_type, tensors)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\", line 617, in map_structure\n",
            "    structure[0], [func(*x) for x in entries],\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\", line 617, in <listcomp>\n",
            "    structure[0], [func(*x) for x in entries],\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\", line 519, in _to_single_numpy_or_python_type\n",
            "    x = t.numpy()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 961, in numpy\n",
            "    maybe_arr = self._numpy()  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 927, in _numpy\n",
            "    return self._numpy_internal()\n",
            "KeyboardInterrupt\n",
            "2020-07-03 04:46:09.724648: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\n",
            "\t [[{{node PyFunc}}]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE1HAtxYAMvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e71b7e6-fe05-440d-93c2-5a386eb4d0d1"
      },
      "source": [
        "#!python3 predict_test.py\n",
        "#%cd /content/foetal-head-segmentation/\n",
        "#%cd foetal-head-us/\n",
        "#!python3 data_preprocessing.py\n",
        "\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "foetal-head-us/test3/\n",
            "(11, 224, 224)\n",
            "... 0 (764, 960)\n",
            "... 1 (764, 960)\n",
            "... 2 (764, 960)\n",
            "... 3 (764, 960)\n",
            "... 4 (540, 800)\n",
            "... 5 (540, 800)\n",
            "... 6 (660, 844)\n",
            "... 7 (660, 844)\n",
            "... 8 ()\n",
            "Traceback (most recent call last):\n",
            "  File \"data_preprocessing.py\", line 20, in <module>\n",
            "    image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
            "cv2.error: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRS2ABtT1W7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39d8023-b937-4014-e67c-180989d87d4f"
      },
      "source": [
        "!python3 predict_test.py"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['head_4.jpg', 'head_3.jpg', 'head_1.jpg', 'head_2.jpg', '002_HC.png', '000_HC.png', 'head_6.jpg', 'head_5.jpg', '.ipynb_checkpoints', '001_HC.png', '003_HC.png']\n",
            "foetal-head-us/test3/\n",
            "['head_4.jpg', 'head_3.jpg', 'head_1.jpg', 'head_2.jpg', '002_HC.png', '000_HC.png', 'head_6.jpg', 'head_5.jpg', '.ipynb_checkpoints', '001_HC.png', '003_HC.png']\n",
            "2022-03-21 06:35:53.847363: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paeWaN3A1h-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4446a7-ba7e-46f6-aa94-957ed01e3444"
      },
      "source": [
        "#%cd foetal-head-us/\n",
        "#%cd test2/\n",
        "\n",
        "# import os\n",
        "# path = os.getcwd()\n",
        "\n",
        "# for i in os.listdir(path):\n",
        "#  print(i,\" ...\")\n",
        "# !pwd\n",
        "# !-rm -r .ipynb_checkpoints\n",
        "#%cd ..\n",
        "#%cd ..\n",
        "#%cd test_demo/\n",
        "#!pwd\n",
        "#!rm -r .ipynb_checkpoints\n",
        "#%cd ..\n",
        "#!python3 predict_test.py\n",
        "# %cd ..\n",
        "# !python3 data_preprocessing.py\n",
        "#%cd /content/foetal-head-segmentation/\n",
        "#%cd ..\n",
        "#!python3 data_preprocessing.py\n",
        "#!python3 predict_test.py\n",
        "#%cd test_demo/\n",
        "#!rm -r .ipynb_checkpoints/\n",
        "#!ls\n",
        "#%cd ..\n",
        "#!python3 predict_test.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_list ['001_HC.png', '003_HC.png', '002_HC.png', 'head_1.jpg', 'head_5.jpg', 'head_3.jpg', '000_HC.png', 'head_2.jpg', 'head_4.jpg', 'head_6.jpg']\n",
            "2022-03-21 08:41:39.696230: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "X_test shape (10, 224, 224)\n",
            "Y-test shape (10, 224, 224, 1)\n"
          ]
        }
      ]
    }
  ]
}